{
 "cells": [
  {
   "cell_type": "raw",
   "id": "ceb26b6d-d77d-4a43-8a72-f9758596005e",
   "metadata": {},
   "source": [
    "---\n",
    "title:\"Why Machines Learn (Reflection: 2)\"\n",
    "description: \"Reflecting on Chapters 3 & 4\"\n",
    "author: \"Eleni\"\n",
    "date: \"11/24/2025\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - Academic\n",
    "  - Reflection\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca43aee-76fc-4241-a2d9-47445349f417",
   "metadata": {},
   "source": [
    "# Reflection on Chapters 3–4 of *Why Machines Learn* by Anil Ananthaswamy  \n",
    "\n",
    "## Chapter 3 – “The Bottom of the Bowl”  \n",
    "\n",
    "Chapter 3 helped me actually *visualize* what “learning” means for a model. Instead of just talking about loss functions and derivatives in an abstract way, Ananthaswamy uses the image of a ball rolling down the side of a bowl. Thinking of the model’s error as a surface, and training as following the steepest downhill direction, made gradient descent feel much more intuitive. It reminded me of doing calculus, but with a more physical, everyday picture attached to it.  \n",
    "\n",
    "![](gradient.png)\n",
    "\n",
    "\n",
    "I also didn’t realize how old some of these ideas are. The discussion of Widrow and Hoff and the LMS algorithm made it clear that machine learning didn’t just appear out of nowhere with modern computers. It was interesting to see how they were already using simple update rules that adjust weights step by step based on error, and how that basic idea still sits underneath a lot of what we call “learning” today. There’s something kind of cool about the fact that you don’t need a perfect global plan—just a way to keep taking small, locally good steps.  \n",
    "\n",
    "The chapter also subtly pushes this idea that “intelligence” can be framed as optimization: minimize the error, find the bottom of the bowl. Part of me finds that a little underwhelming (“Is that all?”), but another part finds it impressive that such a simple principle can scale up into speech recognition, image classification, and all the stuff we see today. It even made me think about my own learning as something like a sloppy gradient descent: I try something, see how wrong I was, and adjust a bit.  \n",
    "\n",
    "At the same time, I was left wondering how far the bowl metaphor really goes. It works nicely for convex problems, but modern deep networks live in giant, messy loss landscapes with lots of bumps and valleys. The chapter hints at this but doesn’t go very deep into how gradient-based methods still manage to find useful solutions in that kind of space. That’s something I’d want to understand better: why does this simple “walk downhill” idea still work when the terrain is so complicated?  \n",
    "\n",
    "\n",
    "## Chapter 4 – “In All Probability”  \n",
    "\n",
    "Chapter 4 shifts from optimization to uncertainty, and it reminded me how bad our intuition about probability usually is. Using the Monty Hall problem as an entry point is almost a jump scare for the brain: most people’s first reaction is wrong, and Ananthaswamy uses that to show why we need more than gut feeling when we’re dealing with uncertain situations. Seeing how the probabilities actually change once Monty opens a door sets up Bayes’ theorem in a way that feels more natural than just throwing the formula on the page.  \n",
    "\n",
    "\n",
    "What stood out to me most was how he connects Bayes to real-world examples like medical tests. The whole idea that even a “99% accurate” test can be misleading when the underlying condition is rare is one of those things that sounds obvious once you’ve seen the math, but still goes against everyday intuition. It’s a good reminder that probability isn’t just a math class topic—it really affects how we interpret risk, evidence, and “certainty.”  \n",
    "\n",
    "The section on naive Bayes classifiers was also helpful because it grounded the theory in an actual model. The independence assumption is clearly unrealistic in most real data, but the fact that these models still perform well in tasks like spam filtering shows how far you can get with simple, approximate assumptions. That seems to be a recurring theme: machine learning often relies on “good enough” simplifications rather than perfectly realistic models.  \n",
    "\n",
    "On a personal level, this chapter made me realize how often I update my beliefs in a vague, hand-wavy way. I’ll hear a piece of information and kind of just “feel” like something is more or less likely, without really thinking about priors or how strong the new evidence is. Bayes’ theorem is basically a formal version of what I’m trying to do in my head—but way more consistent and transparent.  \n",
    "\n",
    "\n",
    "## How Chapters 3 and 4 Fit Together  \n",
    "\n",
    "For me, Chapters 3 and 4 feel like two sides of the same coin. Chapter 3 is about *how* models change—using optimization to move through a landscape and reduce error. Chapter 4 is about *what* those changes mean in terms of uncertainty—how we update our beliefs when we see new data. \n",
    "\n",
    "\n",
    "The big takeaway I’m getting is that there isn’t some mysterious magic at the core of these systems. Underneath the hype, there are loss surfaces, gradients, priors, and likelihoods. But when you stack those tools together and run them at scale, the resulting behavior can look surprisingly intelligent. Ananthaswamy comes across (to me) as cautiously optimistic: he clearly respects the power of these methods, but he also keeps pointing out how limited and unreliable our own intuitions are about optimization and probability.  \n",
    "\n",
    "Overall, these chapters are making me think more carefully about how I talk and think about AI. Instead of just saying “the model learned” in a vague way, I’m starting to ask: what is actually being optimized here? What assumptions about probability are built in? That shift in mindset feels like one of the most useful things I’m getting from the book so far.\n",
    "\n",
    "## Thank You for reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb24a440-597f-4c84-b95c-1c1ee2bd7d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "citation-manager": {
   "items": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
