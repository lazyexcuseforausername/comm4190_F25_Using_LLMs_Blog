{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a7341279-d21e-4afd-8f1a-400ab54480ca",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"What is ChatGPT Doing... And Why Does it Work? - by Wolfram\"\n",
    "description: \"A brief summary & example of Stephen Wolframs article\" \n",
    "author: \"Eleni\"\n",
    "date: \"9/21/2025\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - Education\n",
    "  - Articles\n",
    "  - Probability\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86179d3e-44ee-4222-b9b2-75fe1354390a",
   "metadata": {},
   "source": [
    "In his essay *“What Is ChatGPT Doing… and Why Does It Work?”* Stephen Wolfram tries to explain, in plain language (seriously, its actually very easy to follow!), how models like ChatGPT actually function. \n",
    "\n",
    "TDLR: it’s not “thinking” like a person, but predicting the **next word** in a sequence based on patterns it learned from a huge amount of text. \n",
    "\n",
    "---\n",
    "\n",
    "#### Summary:\n",
    "Stephen Wolfram’s essay *“What Is ChatGPT Doing… and Why Does It Work?”* explains that ChatGPT doesn’t think like a human but instead predicts the next word in a sequence by looking at probabilities learned from massive amounts of text. With billions of examples, the model can mimic many styles of writing and produce responses that feel meaningful, even though it is really just stacking word predictions together.  \n",
    "\n",
    "### Key Ideas  \n",
    "- **Next-word prediction**: ChatGPT chooses the most likely word (or piece of a word) that should come next.  \n",
    "- **Training data**: It has read billions of words from books, websites, and articles, so it can mimic lots of styles and topics.  \n",
    "- **Probabilities**: Instead of one “right” answer, it looks at lots of possible words, each with a probability, and picks the best fit.  \n",
    "- **No real understanding**: It doesn’t “know” facts—it just reflects patterns of how humans write.  \n",
    "\n",
    "--- \n",
    "\n",
    "### For Example \n",
    "If the text is: *“Peanut butter and ___”*  \n",
    "- The model predicts words like “jelly” with high probability, “sandwich” with medium probability, and strange options (like “philosophy”) with very low probability.  \n",
    "\n",
    "This process—repeated over and over—creates full sentences and essays. This is also why if we ask the same question slighlty differently we will recieve different responses. For more on that, check out my blog on tone and politeness with LLMs. \n",
    "\n",
    "---\n",
    "\n",
    "## Demo: Next Word Prediction Game  \n",
    "\n",
    "Here’s a small code cell to show how a simple “next word” prediction idea works.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bbd374d-961e-4a5a-a1e7-9122146c3dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 'peanut butter'\n",
      "Predicted next word: and\n",
      "\n",
      "Input: 'language'\n",
      "Predicted next word: barrier\n"
     ]
    }
   ],
   "source": [
    "# A toy demo of \"next word prediction\"\n",
    "# We use a very tiny fake dataset instead of training an LLM.\n",
    "\n",
    "import random\n",
    "\n",
    "# Simple training data \n",
    "pairs = {\n",
    "    \"peanut butter\": [\"and\"],\n",
    "    \"butter and\": [\"jelly\", \"bread\"],\n",
    "    \"machine\": [\"learning\", \"shop\"],\n",
    "    \"language\": [\"model\", \"barrier\"]\n",
    "}\n",
    "\n",
    "def predict_next_word(text):\n",
    "    words = text.lower().split()\n",
    "    last_two = \" \".join(words[-2:])\n",
    "    if last_two in pairs:\n",
    "        return random.choice(pairs[last_two])\n",
    "    else:\n",
    "        return \"[unknown]\"\n",
    "\n",
    "# Try it out:\n",
    "print(\"Input: 'peanut butter'\")\n",
    "print(\"Predicted next word:\", predict_next_word(\"peanut butter\"))\n",
    "\n",
    "print(\"\\nInput: 'language'\")\n",
    "print(\"Predicted next word:\", predict_next_word(\"language\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d7da89-09cc-4dfe-84de-d0a943306dd9",
   "metadata": {},
   "source": [
    "**Code Explanation:**  \n",
    "The code sets up a small dictionary (`pairs`) that maps short phrases to possible next words. The function `predict_next_word(text)` takes an input phrase, lowers the case, splits it into words, and grabs the last two words (`last_two`). It then checks if those words exist in the dictionary. If they do, it randomly chooses one of the possible next words (`random.choice`). If not, it returns “[unknown].” The `print` statements at the end show how the function works by passing in sample phrases and printing the predictions. This simple structure mirrors how ChatGPT looks at context and picks the next word, just on a much smaller scale. \n",
    "\n",
    "**Create your own dictionary & try it yourself!**\n",
    "\n",
    "*P.S.* here's a link to Wolfram's article\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c263c21a-813f-499f-af5f-8a82b8e59c1f",
   "metadata": {},
   "source": [
    "[Stephen Wolfram – *What Is ChatGPT Doing… and Why Does It Work?*](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd792d1-81d9-41f9-8e95-85ae25d43929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b453a3-71f7-4073-8618-516feb6f0ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
