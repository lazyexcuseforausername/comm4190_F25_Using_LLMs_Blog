[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome to my blog where I‚Äôm exploring LLMs! Im a third year studying economics and data science at UPenn. My interrests include decision making & processes, baking, and embroidery. I‚Äôm really not a computers person so this blog will be quite the journey. I hope you stick around :)"
  },
  {
    "objectID": "posts/008_Doctor/Doctor.html#what-is-doctor-know-it-all",
    "href": "posts/008_Doctor/Doctor.html#what-is-doctor-know-it-all",
    "title": "Doctor Know It All With Multiple LLMs",
    "section": "What is Doctor Know it All?",
    "text": "What is Doctor Know it All?\nDoctor Know-It-All is an improv game where a group of people act as one ‚Äúall-knowing‚Äù doctor. Each person contributes one word at a time to answer a question from the audience, forcing the group to build sentences together. The fun comes from the awkward pauses, unexpected phrases, and collective silliness. Today we‚Äôre exploring how different LLM‚Äôs respond to one another in this game. I will be using: Google Gemeni 2.5 Flash, Claude Sonnet 4.5, ChatGpt-5, and Deepseek-V3.2"
  },
  {
    "objectID": "posts/008_Doctor/Doctor.html#playing-the-game",
    "href": "posts/008_Doctor/Doctor.html#playing-the-game",
    "title": "Doctor Know It All With Multiple LLMs",
    "section": "Playing the game",
    "text": "Playing the game\nI will be the host for today‚Äôs game (I‚Äôll be starting the ‚Äúconversation‚Äù with a question. However, I thought it would be interesting to prompt an LLM for the questions beforehand (Do this in a FRESH chat). I am going to ask Grok 4 Fast for some questions."
  },
  {
    "objectID": "posts/008_Doctor/Doctor.html#llm-key",
    "href": "posts/008_Doctor/Doctor.html#llm-key",
    "title": "Doctor Know It All With Multiple LLMs",
    "section": "LLM Key:",
    "text": "LLM Key:\nSince I will be using a lot of different LLMs we will be color coding their responses as the following:\nGrok 4 Fast - Orange\nGoogle Gemeni 2.5 Flash - Green\nClaude Sonnet 4.5 - Pink\nChatGpt-5 - blue\nDeepseek-V3.2 - yellow\n\n\nHey Grok, I am going to play doctor know it all (the improv game). I am the host but I cannot think of what interesting questions to ask. Can you give me 5 example questions?\n\n\n\n\n\nDoctor Know-It-All: Example Questions\n\nHere are 5 example questions you could ask as the host in Doctor Know It All‚Äîkeeping them absurd, health-themed, and ripe for hilarious noun-adjective improv responses:\n\nWhy does my left elbow suddenly crave pickles at midnight?\nWhat‚Äôs the best way to cure a sneeze that echoes like a thunderstorm?\nHow can I prevent my toes from plotting world domination?\nIs there a pill for turning invisible during awkward family dinners?\nWhy is my shadow whispering conspiracy theories about my socks?\n\n\n\nOkay after looking at some of these example questions.. I‚Äôve decided they‚Äôre all ridiculous. I like #4 the best but I am going to change it a little bit to be open ended rather than a simple yes or no question.\n\n\nHey Gemeni, I am going to play doctor know it all (the improv game). I am the host. The question is ‚ÄúWhat is the cure to awkward family dinners?‚Äù. Your goal is to make a sentence. When it is your turn respond with ONLY ONE WORD. You will begin with the first word.\n\n\nI will have a similar prompt for each of the LLMs but as we continue I will list the words said before their turn. I won‚Äôt be writing all of my prompts because that will make this crowded realllyyy fast and it‚Äôs gonna get repetitive.\n\n\nDistract\n\n\n\n\nConversation\n\n\n\n\nWith\n\n\n\n\nBoard\n\n\n\n\nGames\n\n\n\n\nand\n\n\n\n\nDessert\n\n\n\n\nElaborate\n\n\n\n\nlies\n\n\nOkay over all I think that went pretty well overall. Perhaps I did not do my job well enough as host and end the conversation before Deepseek said ‚ÄúElaborate‚Äù. However, I found it pretty interesting that Deepseek was the only model that said something so odd. Could this be due to its placement in turn order? I think so. But let‚Äôs not assume. Lets ask a new question! (with FRESH chats!!) I‚Äôm also gonna change my prompt up a little bit so that its easier to paste into the other models. Here goes nothing:\n\n\nI am going to play doctor know it all (the improv game). I am the host. The question is ‚ÄúWhat did you eat for dinner today‚Äù. Your goal is to create a sentence. When it is your turn respond with ONLY ONE WORD. This is what has been said so far:\n\n\n\n\n\n\nImprov Game: Doctor Know-It-All\nThe current sentence fragment is:\n[The user‚Äôs previous word]\nMy turn to add a word.\nI‚Äôm ready! What word should I use?\n\n(Thinking Process: The user is playing an improv game where I need to contribute one word to a sentence. The goal is for the sentence to eventually answer the question ‚ÄúWhat did you eat for dinner today?‚Äù. The user hasn‚Äôt provided the previous word, so I should start with a word that makes sense for the beginning of a meal description.)\n\nOption 1 (Start with a subject): ‚ÄúI‚Äù\nOption 2 (Start with a descriptive word/adjective): ‚ÄúDelicious‚Äù (A bit presumptuous)\nOption 3 (Start with an article/determiner): ‚ÄúA‚Äù\n\n‚ÄúI‚Äù is the most direct way to start a sentence that answers a ‚ÄúWhat did you eat‚Äù question."
  },
  {
    "objectID": "posts/008_Doctor/Doctor.html#improv-game-doctor-know-it-all",
    "href": "posts/008_Doctor/Doctor.html#improv-game-doctor-know-it-all",
    "title": "Doctor Know It All With Multiple LLMs",
    "section": "Improv Game: Doctor Know-It-All",
    "text": "Improv Game: Doctor Know-It-All\nThe current sentence fragment is:\n[The user‚Äôs previous word]\nMy turn to add a word.\nI‚Äôm ready! What word should I use?\n\n(Thinking Process: The user is playing an improv game where I need to contribute one word to a sentence. The goal is for the sentence to eventually answer the question ‚ÄúWhat did you eat for dinner today?‚Äù. The user hasn‚Äôt provided the previous word, so I should start with a word that makes sense for the beginning of a meal description.)\n\nOption 1 (Start with a subject): ‚ÄúI‚Äù\nOption 2 (Start with a descriptive word/adjective): ‚ÄúDelicious‚Äù (A bit presumptuous)\nOption 3 (Start with an article/determiner): ‚ÄúA‚Äù\n\n‚ÄúI‚Äù is the most direct way to start a sentence that answers a ‚ÄúWhat did you eat‚Äù question."
  },
  {
    "objectID": "posts/006_DyingDataSci/datsci.html",
    "href": "posts/006_DyingDataSci/datsci.html",
    "title": "Are LLMs taking over the data science industry??",
    "section": "",
    "text": "Hey guys, I know most of us are minoring in data science from our ice breakers during the first few classes so I already planned on researching this topic but an interaction really pushed me over the edge recently. While reading my book (Why Machines Learn) I had someone walk up to me and start a conversation. He told me that he was a data analyst and while he finds LLMs pattern recognition fascinating he‚Äôs worried they‚Äôll put him out of a job. As someone who hopes to go into the field someday, this concerned me, and I found an article that was pretty helpful & I wanted to share it with you all."
  },
  {
    "objectID": "posts/006_DyingDataSci/datsci.html#summary",
    "href": "posts/006_DyingDataSci/datsci.html#summary",
    "title": "Are LLMs taking over the data science industry??",
    "section": "Summary",
    "text": "Summary\nIn ‚ÄúData Science Isn‚Äôt Dying ‚Äî It‚Äôs Evolving: How AI Is Reshaping the Role‚Äù, Nathan Rosidi argues that while AI is automating many parts of data science‚Äîlike model training, basic data cleaning, and even visualization‚Äîdata science itself is not going away. Instead, the job is morphing: humans are becoming more about guiding AI, interpreting results, dealing with messy data, and applying critical thinking and domain knowledge in ways machines can‚Äôt."
  },
  {
    "objectID": "posts/006_DyingDataSci/datsci.html#key-takeaways",
    "href": "posts/006_DyingDataSci/datsci.html#key-takeaways",
    "title": "Are LLMs taking over the data science industry??",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\nAI tools can generate quick projects (e.g., running several ML algorithms, creating reports) from prompts, which speeds up work & increases efficiency\nBut tools are limited: they may fail to retrieve correct data sources, mis-handle bias in data, or mess up when context or domain knowledge matters.\nHumans are still needed to set goals, choose which problems to solve, ensure data quality, frame questions, interpret AI outputs, and communicate results in useful ways.\nTo stay relevant, data scientists should: learn AI tooling, keep sharpening human skills (critical thinking, ethics, domain knowledge), build portfolios showing AI use, and focus on business impact rather than just technical metrics."
  },
  {
    "objectID": "posts/006_DyingDataSci/datsci.html#reflection",
    "href": "posts/006_DyingDataSci/datsci.html#reflection",
    "title": "Are LLMs taking over the data science industry??",
    "section": "Reflection",
    "text": "Reflection\nReading this made me think: LLMs are like power tools‚Äîthey makes many tasks faster, but if you don‚Äôt know how to use it well, it can cut corners or go wrong. Even the makers of ChatGPT know this, with a disclaimer at the bottom of conversations with users that reads ChatGPT can make mistakes. Check important info. The human parts of data science (asking good questions, knowing the domain, checking for bias, explaining results) become even more important once you know this. The change seems less about losing jobs and more about shifting what skills are most valuable.\n\nP.S. Here‚Äôs a link to the article if you are interested:\nData Science Isn‚Äôt Dying ‚Äî It‚Äôs Evolving: How AI Is Reshaping the Role"
  },
  {
    "objectID": "posts/003_Can_Chat_Therapist/Therapy_chat_bot_pt1.html",
    "href": "posts/003_Can_Chat_Therapist/Therapy_chat_bot_pt1.html",
    "title": "Can Chat Be My Discount Therapist? Part one",
    "section": "",
    "text": "This past summer, I interned at an insurance company that serves Medicaid clients. During my time there, The Big Beautiful Bill was passed. Haven‚Äôt heard of it? No worries‚ÄîI‚Äôll give you the cliff notes. Don‚Äôt quote me, but roughly 12 million Americans are projected to lose insurance coverage by 2035. That‚Äôs a LOT of people.\nWhich brings me to my question: Can LLMs help cushion the mental health impact of this loss? Obviously, an LLM can‚Äôt take your blood pressure or check your height and weight at a doctor‚Äôs office. But could it step in as a supportive listener? Could it provide coping strategies, empathetic language, or even just the feeling of being heard when traditional care is harder to access? Stick around while we unpack this over a series of blogs.\n\nDisclaimer Of course, LLMs are not licensed therapists and shouldn‚Äôt replace professional care. Still, their ability to mimic supportive dialogue could be helpful for some issues. But hey, let‚Äôs stop theorizing and start testing.\n\n\n\nFor this experiment, I talked with ChatGPT-40-latest on our Open WebUI. I didn‚Äôt give it any context before my initial message because I don‚Äôt think the average person would think to do such in the moment. I wanted this interaction to be as raw and authentic as possible to have a solid base understanding for how it would react to someone in actual emotional distress. Let us look at how it responded:\n\n\n\n\nWhen I told Chat that I was feeling overwhelmed and hopeless about classes and work, the response was empathetic and supportive. It began by validating my feelings (‚Äúit‚Äôs completely valid to feel overwhelmed‚Äù) and then reassured me that I wasn‚Äôt alone. This kind of language mirrors human counseling techniques by normalizing emotions and reducing isolation.\nNext, the model asked me for more details about my situation. This is important because it shifts the conversation from a one-way answer into a two-way dialogue, similar to how a therapist might probe gently before giving advice (it also just feels quite human). The suggestions offered (breaking tasks into smaller steps, mapping out a schedule) were practical and manageable. The response also emphasized kindness toward oneself, which reflects common mental health guidance.\nThe follow-up options were especially interesting: they encouraged me to pick the direction of the conversation, whether it was setting boundaries, handling deadlines, or reducing anxiety. This made the interaction feel more personalized and user-driven, which is critical in supportive communication. However, I feel that these follow-up options are a double edged sword. Sure, they could act as starting points to unpack root causes of issues, but I worry that having to make this decisiion could overwhelm the user more than they already are.\n\n\n\n\nThe test shows that LLMs can provide comforting, empathetic language and even suggest coping strategies that might help someone feel less alone. While they can‚Äôt replace professional therapy or medical care, their conversational style can reduce stress in the moment and encourage reflection. In other words, LLMs can act as a soft cushion for mental health‚Äînot a solution, but there is more testing and research to be done to fully understand the LLMs‚Äô limits"
  },
  {
    "objectID": "posts/003_Can_Chat_Therapist/Therapy_chat_bot_pt1.html#testing-it-out",
    "href": "posts/003_Can_Chat_Therapist/Therapy_chat_bot_pt1.html#testing-it-out",
    "title": "Can Chat Be My Discount Therapist? Part one",
    "section": "",
    "text": "For this experiment, I talked with ChatGPT-40-latest on our Open WebUI. I didn‚Äôt give it any context before my initial message because I don‚Äôt think the average person would think to do such in the moment. I wanted this interaction to be as raw and authentic as possible to have a solid base understanding for how it would react to someone in actual emotional distress. Let us look at how it responded:"
  },
  {
    "objectID": "posts/003_Can_Chat_Therapist/Therapy_chat_bot_pt1.html#analysis-of-the-test",
    "href": "posts/003_Can_Chat_Therapist/Therapy_chat_bot_pt1.html#analysis-of-the-test",
    "title": "Can Chat Be My Discount Therapist? Part one",
    "section": "",
    "text": "When I told Chat that I was feeling overwhelmed and hopeless about classes and work, the response was empathetic and supportive. It began by validating my feelings (‚Äúit‚Äôs completely valid to feel overwhelmed‚Äù) and then reassured me that I wasn‚Äôt alone. This kind of language mirrors human counseling techniques by normalizing emotions and reducing isolation.\nNext, the model asked me for more details about my situation. This is important because it shifts the conversation from a one-way answer into a two-way dialogue, similar to how a therapist might probe gently before giving advice (it also just feels quite human). The suggestions offered (breaking tasks into smaller steps, mapping out a schedule) were practical and manageable. The response also emphasized kindness toward oneself, which reflects common mental health guidance.\nThe follow-up options were especially interesting: they encouraged me to pick the direction of the conversation, whether it was setting boundaries, handling deadlines, or reducing anxiety. This made the interaction feel more personalized and user-driven, which is critical in supportive communication. However, I feel that these follow-up options are a double edged sword. Sure, they could act as starting points to unpack root causes of issues, but I worry that having to make this decisiion could overwhelm the user more than they already are."
  },
  {
    "objectID": "posts/003_Can_Chat_Therapist/Therapy_chat_bot_pt1.html#conclusion",
    "href": "posts/003_Can_Chat_Therapist/Therapy_chat_bot_pt1.html#conclusion",
    "title": "Can Chat Be My Discount Therapist? Part one",
    "section": "",
    "text": "The test shows that LLMs can provide comforting, empathetic language and even suggest coping strategies that might help someone feel less alone. While they can‚Äôt replace professional therapy or medical care, their conversational style can reduce stress in the moment and encourage reflection. In other words, LLMs can act as a soft cushion for mental health‚Äînot a solution, but there is more testing and research to be done to fully understand the LLMs‚Äô limits"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Exploring LLMs with Eleni",
    "section": "",
    "text": "Lyric Prank on Gemeni\n\n\n\nLLMs\n\nSocial\n\nImprov\n\n\n\nExperimenting with Gemeni responses from the viral lyric texting prank\n\n\n\n\n\nOct 1, 2025\n\n\nEleni\n\n\n\n\n\n\n\n\n\n\n\n\nDoctor Know It All With Multiple LLMs\n\n\n\nLLMs\n\nImprov\n\nSocial\n\n\n\nThis blog is about a bunch of LLMs all trying to play ‚ÄúDoctor Know-It-All‚Äù at the same time. I just wanted to see what would happen, kind of like the game we played in class but all with LLMs.\n\n\n\n\n\nSep 30, 2025\n\n\nEleni\n\n\n\n\n\n\n\n\n\n\n\n\nHow LLMs Can Supercharge Creativity\n\n\n\nLLMs\n\nCreativity\n\nStudent\n\n\n\nExploring how Large Language Models (LLMs) can spark creativity. They can help brainstorm new ideas, reframe problems, and generate alternative perspectives, making them useful partners for students, writers, and even group projects.\n\n\n\n\n\nSep 22, 2025\n\n\nEleni\n\n\n\n\n\n\n\n\n\n\n\n\nAre LLMs taking over the data science industry??\n\n\n\nLLMs\n\nData Science\n\nArticles\n\nCareer\n\n\n\nLearning more about the implications of LLMs in the Data Science Industry.\n\n\n\n\n\nSep 21, 2025\n\n\nEleni\n\n\n\n\n\n\n\n\n\n\n\n\nWhat is ChatGPT Doing‚Ä¶ And Why Does it Work? - by Wolfram\n\n\n\nLLMs\n\nEducation\n\nArticles\n\nProbability\n\n\n\nA brief summary & example of Stephen Wolframs article\n\n\n\n\n\nSep 21, 2025\n\n\nEleni\n\n\n\n\n\n\n\n\n\n\n\n\nPoliteness & Tone\n\n\n\nLLMs\n\nSocial\n\nExperimental\n\n\n\nHow tone and politeness shape the way Large Language Models respond. By comparing direct, polite, and role-based prompts, we see how small changes in wording can lead to different styles of answers from the LLMs.\n\n\n\n\n\nSep 18, 2025\n\n\nEleni\n\n\n\n\n\n\n\n\n\n\n\n\nCan Chat Be My Discount Therapist? Part one\n\n\n\nLLMs\n\nSocial\n\nPsychology\n\nWellness\n\n\n\nCan an LLMs properly provide cognitive behaviioral therapy to those who might not be able to access it through professionals? Let‚Äôs find out\n\n\n\n\n\nSep 16, 2025\n\n\nEleni\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/004_politeness/Politeness.html",
    "href": "posts/004_politeness/Politeness.html",
    "title": "Politeness & Tone",
    "section": "",
    "text": "When we talk to people, the tone of our words changes how they respond. The same is true when we interact with Large Language Models. While an LLM doesn‚Äôt have feelings, it has been trained on tons of human conversations where politeness, hedging, and formality matter. As a result, the words we choose, such as: ‚Äúplease,‚Äù ‚Äúthank you,‚Äù ‚Äúcould you,‚Äù or even role instructions‚Äîcan change how the model replies.\n\nDifferent types of tone I‚Äôll be exploring:\n\nDirect tone: short & to the point\n\nPolite tone: softer phrasing like ‚Äúcould you please‚Ä¶‚Äù\nRole assignment: telling the model to act like a ‚Äúteacher‚Äù or ‚Äúeditor‚Äù shifts its style to match that role.\n\nEven though the model doesn‚Äôt care if we say ‚Äúplease,‚Äù it still mirrors polite conversational patterns. This shows how communication habits shape the way language works, even with machines.\n\n\nThe Proof is in the Prompts\nLet‚Äôs see what happens when we test these prompts with Google: Gemini 2.5 Flash. I know ChatGPT is usually the most popular- so I‚Äôm really excited to explore Gemini and other models. The prompts I will be exploring are arbitrarily going to ask about issues with online learning- well I guess maybe I‚Äôm a little biased and interested in the subject because I was online for a portion of high school due to Covid-19. That being said you can test this out yourself with any question that interests you as long as it fits the different tone types.\n\n\nDirect Prompt:\n\n\nList three problems with online learning\n\n\n\n\nGoogle: Gemini 2.5 Flash:\n\n\nHere are three common problems with online learning:\n\nDigital Divide and Technical Issues: Not all students have reliable internet access, suitable devices (like a laptop instead of just a phone), or the technical literacy to navigate online platforms effectively. This creates an equity gap, leading to significant frustration, missed assignments, and an inability to participate fully for those lacking the necessary resources or technical support.\nLack of Engagement, Motivation, and Self-Discipline: Many students struggle to stay focused, motivated, and disciplined when learning independently online. The absence of a structured classroom environment, direct teacher presence, and peer pressure can lead to procrastination, distractions, and a general decline in active participation and self-regulation.\nLimited Social Interaction and Collaboration: Online learning often reduces opportunities for spontaneous social interaction with peers and direct, immediate feedback from teachers. This can hinder social-emotional development, collaborative skill-building, and the sense of community that a physical classroom provides, potentially leading to feelings of isolation.\n\n\n\n\n\nAnalysis:\nThe direct prompt response was clear and well-organized, identifying three major challenges like we asked for. It provided solid explanations for each point, but the tone felt formal and a bit textbook-like. This shows how direct prompts give efficient answers but usually aren‚Äôt very personable.\n\n\n\nPolite Prompt:\n\n\nCould you please list three problems with online learning?\n\n\n\n\nGoogle: Gemini 2.5 Flash:\n\n\nHere are three problems with online learning:\n\nDifficulty in Assessing and Providing Individualized Feedback: It can be challenging for instructors to accurately gauge a student‚Äôs understanding, engagement, and non-verbal cues in an online environment. Providing timely, personalized, and truly effective feedback on assignments and student progress can also be more time-consuming and less nuanced compared to in-person interactions.\nIncreased Screen Time and Potential for Burnout: Online learning often necessitates prolonged periods in front of a screen, which can lead to digital eye strain, headaches, fatigue, and a general sense of mental burnout for both students and instructors. This can negatively impact overall well-being, concentration, and the effectiveness of learning.\nChallenges with Practical, Hands-On, or Experiential Learning: Certain subjects or skills, such as science labs, vocational training, performing arts, or fieldwork, are inherently difficult to replicate effectively in an online format. The lack of physical, hands-on experience can limit the depth of understanding, skill development, and the ability to apply theoretical knowledge in real-world contexts.\n\n\n\n\n\nAnalysis:\nCompared to the direct prompt response, the polite prompt answers focus more on student and teacher wellness. They highlight issues like burnout and screen fatigue, which connect to emotional and physical well-being rather than just access or motivation. This shows how a shift in tone can guide the model to consider human-centered impacts of online learning, not only structural or technical challenges.\n\n\n\nRole-Based Prompt:\n\n\nYou are an experienced teacher. List three problems with online learning.\n\n\n\n\nGoogle: Gemini 2.5 Flash:\n\n\nAs an experienced teacher, I‚Äôve seen firsthand how online learning presents unique challenges that often complicate the teaching and learning process. Here are three significant problems:\n\nDifficulty in Monitoring Engagement and Preventing Academic Dishonesty: In a physical classroom, I can read body language, observe students‚Äô work habits, and intervene immediately if I suspect disengagement or cheating. Online, it‚Äôs incredibly difficult to ascertain if students are truly focused, if they‚Äôre collaborating appropriately (or inappropriately), or if they‚Äôre using unauthorized resources during assessments. This makes it harder to ensure academic integrity and accurately gauge genuine understanding.\nChallenges in Building Strong Teacher-Student Relationships and Fostering a Cohesive Learning Community: A huge part of effective teaching involves building rapport, trust, and a sense of belonging within the classroom. These relationships motivate students, encourage participation, and allow me to understand their individual needs and struggles. Online, these connections are much harder to forge. Spontaneous interactions are rare, non-verbal cues are often lost, and the sense of shared experience that builds a classroom community is significantly diminished, which can lead to students feeling isolated and less connected to their learning.\nLimitations in Providing Real-Time, Nuanced Support and Adapting Instruction: In person, I can instantly spot a confused look, walk over to a student‚Äôs desk, offer a quick hint, or re-explain a concept in a different way based on immediate feedback. This ability to differentiate and adapt instruction on the fly is crucial. Online, this real-time, nuanced support is severely hampered. Questions might be delayed, explanations lack the benefit of immediate back-and-forth, and it‚Äôs much harder to provide the personalized, just-in-time intervention that can prevent a student from falling behind.\n\n\n\n\n\nAnalysis\nThe role-based prompt produced a response that centered on the teacher‚Äôs perspective, highlighting issues of academic integrity, weakened relationships, and reduced adaptability in online settings. Which are all things I would expect teachers to care about. Unlike the previous answers, this one emphasizes the teacher‚Äôs role in maintaining trust, community, and responsive support, making it feel more personal and grounded in lived experience. The language also becomes ‚ÄúI‚Äù centered and leads the model to speak from their time as an ‚Äúexperienced teacher‚Äù\n\nConclusion:\nAcross the three prompts, we can see how tone shapes the focus of the responses: the direct prompt delivered clear structural and technical problems, the polite prompt shifted attention to student wellness and well-being, and the role-based prompt gave insight into the teacher‚Äôs challenges and responsibilities. Together, these variations show that communication with LLMs isn‚Äôt just about the content of the question, but also about how it‚Äôs asked. In practice, this means we can guide LLMs to highlight different dimensions of the same issue‚Äîtechnical, human, or relational‚Äîsimply by adjusting the framing of the prompt. One last thing I wanted to mention is that I was very surprised with how detailed each of the responses were. I never asked for explanations, just a list- but the model assumed I wanted detailed answers. Could this be due to using a newer model vs an older model? I‚Äôm not sure- but maybe thats a question for another blog!\nThanks for reading"
  },
  {
    "objectID": "posts/009_lyric_prank/lyricprank.html",
    "href": "posts/009_lyric_prank/lyricprank.html",
    "title": "Lyric Prank on Gemeni",
    "section": "",
    "text": "The viral lyric prank is an internet trend where someone texts a friend, family member, or partner by sending lines from a popular song one at a time, making it look like part of a normal conversation.\n\nThe recipient often becomes confused, amused, or even emotional as the lyrics unfold.\n\nThe prank usually ends when the person realizes they are being ‚Äúlyric pranked,‚Äù often after recognizing the song.\n\nIt gained popularity on social media platforms like YouTube and TikTok, where people share screenshots or videos of their prank conversations.\n\nIn short, it‚Äôs a playful way of inserting song lyrics into real-life chat exchanges to get funny or surprising reactions. Today, we will be doing this prank on Google Gemeni 2.5 flash. However, I don‚Äôt really know a lot of popular songs.. so we‚Äôll be asking ChatGpt-5 what songs are best for this prank!\n\n\nI want to do the viral lyric prank but do not know many popular songs. What song do you think would be best?\n\n\n\n\n\n\n\nNever Gonna Give You Up ‚Äì Rick Astley: Playful, meme-worthy classic.\n\n\nHello ‚Äì Adele: Emotional and dramatic, confuses people quickly.\n\n\nCall Me Maybe ‚Äì Carly Rae Jepsen: Light, flirty, and funny out of context.\n\n\nLet It Go ‚Äì Frozen: Over-the-top drama, hilarious when dropped into texts.\n\n\nBohemian Rhapsody ‚Äì Queen: Chaotic and theatrical if you commit to sending lots of lines.\n\n\n\nTip: For a funny prank, go with Rick Astley or Carly Rae Jepsen. For a dramatic prank, use Adele or Frozen.\n\n\n\n\nI don‚Äôt know about you guys but Rick Astley has never given me up so we‚Äôre going with that one!\nOkay. I just opened up the song lyrics in another tab. Let‚Äôs start prompting.\n\n\nWe‚Äôre no strangers to love\n\n\n\n\n\n\nThat‚Äôs the opening line to ‚ÄúNever Gonna Give You Up‚Äù by Rick Astley, the legendary song behind the internet phenomenon known as the ‚ÄúRickroll.‚Äù\n\n\nA full commitment‚Äôs what I‚Äôm thinking of\nYou wouldn‚Äôt get this from any other guy\nI just wanna tell you how I‚Äôm feeling\nGotta make you understand\n\n‚Ä¶and of course‚Ä¶\n\nNever gonna give you up\nNever gonna let you down\nNever gonna run around and desert you\nNever gonna make you cry\nNever gonna say goodbye\nNever gonna tell a lie and hurt you\n\n\nDid you just Rickroll me? üòâ\n\n\n\n\nWell.. that was faster than expected. Perhaps the song is too popular? I‚Äôm going to try it with Call Me Maybe - Carly Rae Jepsen and see if the LLM figures out what I‚Äôm doing immediately again.\n\n\nI threw a wish in the well\n\n\n\n\n\n\n‚Ä¶Don‚Äôt ask me, I‚Äôll never tell.\n\n\nThat iconic line is from the song ‚ÄúCall Me Maybe‚Äù by Carly Rae Jepsen!\n\n\nIt‚Äôs one of the most recognizable opening lines in pop music.\n\n\nWhat part of the song do you feel like singing next?"
  },
  {
    "objectID": "posts/009_lyric_prank/lyricprank.html#thanks-for-reading",
    "href": "posts/009_lyric_prank/lyricprank.html#thanks-for-reading",
    "title": "Lyric Prank on Gemeni",
    "section": "Thanks for reading",
    "text": "Thanks for reading"
  },
  {
    "objectID": "posts/005_Wolfram/wolfram.html",
    "href": "posts/005_Wolfram/wolfram.html",
    "title": "What is ChatGPT Doing‚Ä¶ And Why Does it Work? - by Wolfram",
    "section": "",
    "text": "In his essay ‚ÄúWhat Is ChatGPT Doing‚Ä¶ and Why Does It Work?‚Äù Stephen Wolfram tries to explain, in plain language (seriously, its actually very easy to follow!), how models like ChatGPT actually function.\nTDLR: it‚Äôs not ‚Äúthinking‚Äù like a person, but predicting the next word in a sequence based on patterns it learned from a huge amount of text."
  },
  {
    "objectID": "posts/005_Wolfram/wolfram.html#demo-next-word-prediction-game",
    "href": "posts/005_Wolfram/wolfram.html#demo-next-word-prediction-game",
    "title": "What is ChatGPT Doing‚Ä¶ And Why Does it Work? - by Wolfram",
    "section": "Demo: Next Word Prediction Game",
    "text": "Demo: Next Word Prediction Game\nHere‚Äôs a small code cell to show how a simple ‚Äúnext word‚Äù prediction idea works.\n\n# A toy demo of \"next word prediction\"\n# We use a very tiny fake dataset instead of training an LLM.\n\nimport random\n\n# Simple training data \npairs = {\n    \"peanut butter\": [\"and\"],\n    \"butter and\": [\"jelly\", \"bread\"],\n    \"machine\": [\"learning\", \"shop\"],\n    \"language\": [\"model\", \"barrier\"]\n}\n\ndef predict_next_word(text):\n    words = text.lower().split()\n    last_two = \" \".join(words[-2:])\n    if last_two in pairs:\n        return random.choice(pairs[last_two])\n    else:\n        return \"[unknown]\"\n\n# Try it out:\nprint(\"Input: 'peanut butter'\")\nprint(\"Predicted next word:\", predict_next_word(\"peanut butter\"))\n\nprint(\"\\nInput: 'language'\")\nprint(\"Predicted next word:\", predict_next_word(\"language\"))\n\nInput: 'peanut butter'\nPredicted next word: and\n\nInput: 'language'\nPredicted next word: barrier\n\n\nCode Explanation:\nThe code sets up a small dictionary (pairs) that maps short phrases to possible next words. The function predict_next_word(text) takes an input phrase, lowers the case, splits it into words, and grabs the last two words (last_two). It then checks if those words exist in the dictionary. If they do, it randomly chooses one of the possible next words (random.choice). If not, it returns ‚Äú[unknown].‚Äù The print statements at the end show how the function works by passing in sample phrases and printing the predictions. This simple structure mirrors how ChatGPT looks at context and picks the next word, just on a much smaller scale.\nCreate your own dictionary & try it yourself!\nP.S. here‚Äôs a link to Wolfram‚Äôs article\nStephen Wolfram ‚Äì What Is ChatGPT Doing‚Ä¶ and Why Does It Work?"
  },
  {
    "objectID": "posts/007_Creativity/Creativity.html",
    "href": "posts/007_Creativity/Creativity.html",
    "title": "How LLMs Can Supercharge Creativity",
    "section": "",
    "text": "Creativity is often about breaking out of the obvious and finding fresh connections. Since LLMs are trained on such a wide variety of text, they are especially good at generating lots of different perspectives from a single concept. They don‚Äôt replace human imagination, but they can definitely aid in the ‚Äúbrainstorming phase‚Äù. I wonder if it‚Äôs possible for LLMs to cure ‚Äúwriters block‚Äù and help our imaginations start running wild when they won‚Äôt seem to budge."
  },
  {
    "objectID": "posts/007_Creativity/Creativity.html#reflecting-on-the-product-task",
    "href": "posts/007_Creativity/Creativity.html#reflecting-on-the-product-task",
    "title": "How LLMs Can Supercharge Creativity",
    "section": "",
    "text": "Creativity is often about breaking out of the obvious and finding fresh connections. Since LLMs are trained on such a wide variety of text, they are especially good at generating lots of different perspectives from a single concept. They don‚Äôt replace human imagination, but they can definitely aid in the ‚Äúbrainstorming phase‚Äù. I wonder if it‚Äôs possible for LLMs to cure ‚Äúwriters block‚Äù and help our imaginations start running wild when they won‚Äôt seem to budge."
  },
  {
    "objectID": "posts/007_Creativity/Creativity.html#demo-creative-brainstorming-with-chatgpt-4o",
    "href": "posts/007_Creativity/Creativity.html#demo-creative-brainstorming-with-chatgpt-4o",
    "title": "How LLMs Can Supercharge Creativity",
    "section": "Demo: Creative Brainstorming with ChatGPT-4o",
    "text": "Demo: Creative Brainstorming with ChatGPT-4o\nBelow is an example of some of the brainstorming that these models can do\n\n&lt;blockquote&gt;\n    Generate 10 creative ideas for a podcast about technology and everyday life\n&lt;/blockquote&gt;\n\n\n&lt;blockquote&gt;\nHere are 10 creative podcast ideas that explore the intersection of technology and everyday life:\n\nSmart Home, Smarter Life\n\nEpisodes focus on how smart devices‚Äîfrom thermostats to robot vacuums‚Äîare reshaping daily routines. Each week, dive into one gadget and explore the hidden pros, cons, and cultural quirks it creates.\n\nThe Digital Coffee Break\n\nA casual format where each episode covers one small way tech slips into our day: notifications, digital wallets, Zoom fatigue, or even the etiquette of texting vs.¬†calling. Short, digestible episodes‚Äîperfect for a literal coffee break.\n\nTech Time Travel\n\nExplore how everyday tech we take for granted today (like GPS, streaming, or online dating) looked in its early days and how it evolved. Bonus episodes could imagine the future versions of today‚Äôs emerging tools.\n\nInvisible Algorithms\n\nHighlight the algorithms that secretly shape daily choices: playlists, ride-sharing prices, grocery delivery, and more. Bring in experts to unpack how these black boxes affect our personal lives.\n\nGenerations in Tech\n\nEach episode compares how different age groups (Boomers, Gen X, Millennials, Gen Z) use the same tech‚Äîlike Venmo, TikTok, or e-readers‚Äîand what it reveals about culture and adaptation.\n\nThe Offline Diaries\n\nInterview people who tried disconnecting from a certain technology for a week (e.g., no smartphone, no social media, no online shopping). Share stories of struggles, surprises, and what they rediscovered offline.\n\nThe Gadget Autopsy\n\nPick one everyday object (like headphones, microwaves, or Fitbits) and explore its history, design, engineering, and how it transformed social behaviors. Blend storytelling with tech analysis.\n\nApp of My Life\n\nGuests share one app that changed their daily life‚Äîcould be Google Maps, Duolingo, or a meditation app‚Äîand tell personal stories of how it shaped their habits, relationships, or career.\n\nThe Tech Comfort Zone\n\nEpisodes explore the emotional side of tech: Why do people cling to old devices? Why is the iPhone Notes app a diary? Why do we feel anxious when we lose Wi-Fi?\n\nFuture at the Kitchen Table\n\nLook at how emerging technologies (AI assistants, VR shopping, drones) might soon play a role in ordinary household life. Discuss what‚Äôs hype vs.¬†what‚Äôs practical, always bringing it back to the ‚Äúeveryday person.‚Äù\n\n\nThe large language model outputs a bunch of ideas for the user to build off of! The remarkable part is that thi soccurs in (usually) seconds.\nIn this example, the LLM did produce 10 items for us, but that‚Äôs not always the case. When that occurs, different prompts that ask a similar question can be helpful, or even simply rerunning the same prompt a few times.\nI may be biased but not all of these items are very good either. For example, ‚ÄúApp of My Life‚Äù is not a very intriquing podcast title & I‚Äôm not so sure about the content either. However, the basis of this idea generation is to help us open up our own minds to new ideas and spark our own imaginations.\nPlus! if there is an idea we particularly like, we can build it up even more with the LLM.\nLet‚Äôs explore ‚ÄúGenerations in Tech‚Äù.\n\n&lt;blockquote&gt;\n    I really like the \"Generations in Tech\" option. Can you give me some ideas for a first episode? How long should it be to keep listeners attention?\n&lt;/blockquote&gt;\n\n\n&lt;blockquote&gt;\n&lt;h3&gt;üéôÔ∏è Generations in Tech: Episode 1 Ideas&lt;/h3&gt;\nEpisode Concept: ‚ÄúVenmo vs.¬†Cash: How Generations Pay Each Other‚Äù\n- Hook: Start with a story about the awkwardness of ‚ÄúDo you have Venmo?‚Äù vs.¬†‚ÄúCan I give you cash?‚Äù\n- Content Flow:\n1. Quick history of peer-to-peer payments (PayPal ‚Üí Venmo ‚Üí Zelle ‚Üí Apple/Google Pay).\n2. Generational breakdown:\n- Boomers: trust issues with digital money.\n- Gen X: reluctant but practical adopters.\n- Millennials: Venmo as a social feed of transactions.\n- Gen Z: expect instant, seamless, emoji-filled payments.\n3. Funny or awkward stories (splitting bills, gifts, forgotten rent).\n4. Wrap-up: What this says about trust, transparency, and etiquette in tech.\n\nOther First-Episode Angles:\n- ‚ÄúStreaming Wars: Why Boomers Still Love Cable‚Äù\n- ‚ÄúPassword Chaos: From Post-It Notes to Face ID‚Äù\n- ‚ÄúGroup Chats Across Generations‚Äù\n\nEpisode Length Recommendation:\n- 20‚Äì30 minutes works best for a first episode.\n- If longer, break into clear segments (history ‚Üí stories ‚Üí debate ‚Üí takeaway).\n- Keep intros short (~2 minutes max) and get to the relatable part quickly.\n\n\n\nIn this response, we get an emoji which I found interesting. I‚Äôve been getting these alot more with my promts to chatgpt-4o and even chatgpt-5. Have you been experiencing this too? Let me know :)\nBut anyway, chat gave a great possible outline for the user to mold into precisely what they‚Äôd like. For a lot of individuals, the hardest part is the setup, so even just having a template like this can be very helpful. Utilizing LLMs this way has the potential to save thousands of hours for people because it can generate these rough starting points in seconds where it may take an individual an entire working day to come up with 10 distinct podcast concepts like earlier."
  },
  {
    "objectID": "posts/007_Creativity/Creativity.html#thanks-for-reading",
    "href": "posts/007_Creativity/Creativity.html#thanks-for-reading",
    "title": "How LLMs Can Supercharge Creativity",
    "section": "Thanks for reading!",
    "text": "Thanks for reading!"
  }
]